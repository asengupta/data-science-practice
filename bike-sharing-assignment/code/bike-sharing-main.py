# # Running the file
# If you wish to use your own copy of the data, use the following command:
#
# ``python bike-sharing-main.py [{-i |--input=}<bike-share-csv>] [-h | --help]``
#
# Here are some examples:
#
# ``python bike-sharing-main.py --input=day.csv``
# ``python bike-sharing-main.py -i day.csv``
# ``python bike-sharing-main.py``
# ``python bike-sharing-main.py --help``
#
# All of these arguments are optional. Providing no arguments makes the code read from the default location, i.e. ```./data```.
#
# # Instructions on regenerating this Jupyter Notebook
# The Jupyter notebook can be regenerated by installing P2J, like so:
#
# ``pip install p2j``
#
# and running the following:
#
# ``p2j -o code/bike-sharing-main.py -t notebook/bike-sharing-main.ipynb``

# # Library Imports
import getopt
import logging
import sys
import warnings

import pandas as pd
from sklearn.model_selection import train_test_split

DEFAULT_DATASET_LOCATION = "../data"
DEFAULT_BIKE_SHARE_CSV_FILENAME = "day.csv"


class SeasonConstants:
    SEASON_1 = "spring"
    SEASON_2 = "summer"
    SEASON_3 = "fall"
    SEASON_4 = "winter"


class WeatherConstants:
    WEATHER_1 = "Clear, Few clouds, Partly cloudy, Partly cloudy"
    WEATHER_2 = "Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist"
    WEATHER_3 = "Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds"
    WEATHER_4 = "Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog"


season_categorical_mapping = {1: SeasonConstants.SEASON_1,
                              2: SeasonConstants.SEASON_2,
                              3: SeasonConstants.SEASON_3,
                              4: SeasonConstants.SEASON_4}

weather_categorical_mapping = {1: WeatherConstants.WEATHER_1,
                               2: WeatherConstants.WEATHER_2,
                               3: WeatherConstants.WEATHER_3,
                               4: WeatherConstants.WEATHER_4}


class Columns:
    SEASON = "season"
    WEATHER = "weathersit"
    DATE = "dteday"
    DAY = "day"
    INSTANT = "instant"


# ## Null Column Cleanup
# The loan dataset has several columns which are completely empty. These are useless for analysis.
# This function drops completely null columns.
def without_null_columns(bikeshares):
    heading("Null Entries Statistics")
    null_entry_statistics = bikeshares.isnull().sum() / len(bikeshares.index)
    logging.info(null_entry_statistics)
    null_columns = null_entry_statistics[null_entry_statistics == 1.0].index.to_numpy()
    heading("Completely Null Columns")
    logging.info(null_columns)
    return bikeshares.drop(null_columns, axis=1)


def with_day(bikeshares):
    dates = pd.to_datetime(bikeshares.pop(Columns.DATE), format='%d-%m-%Y')
    log_df("Dates", dates)
    bikeshares[Columns.DAY] = pd.DatetimeIndex(dates).day
    log_df("Bikeshares with Day", bikeshares, 200)
    return bikeshares


def explore(bikeshares):
    pass

# # Entry Point for CRISPR
#  This function is the entry point for the entire CRISPR process. This is called by `main()`
def study(raw_bike_share_data):
    logging.debug(raw_bike_share_data.head().to_string())
    logging.debug(raw_bike_share_data.shape)
    logging.debug(raw_bike_share_data.columns)
    bikeshares = without_null_columns(raw_bike_share_data)
    log_df("Weather 4 data point does not exist in dataset", bikeshares[bikeshares[Columns.WEATHER] == 4])
    bikeshares_master = prepared(bikeshares)
    log_df("BIKESHARES", bikeshares_master, 10)
    bikeshares_training, bikeshares_test = test_train_split(bikeshares_master)
    explore(bikeshares_training)


def test_train_split(bikeshares_master):
    bikeshares_training, bikeshares_test = train_test_split(bikeshares_master, train_size=0.7, test_size=0.3,
                                                            random_state=100)
    heading("TEST / TRAIN SPLIT")
    logging.info(f"Training set has {len(bikeshares_training)} vectors")
    logging.info(f"Test set has {len(bikeshares_test)} vectors")
    return bikeshares_training, bikeshares_test


def prepared(bikeshares):
    bikeshares_without_unneeded_columns = bikeshares.drop(Columns.INSTANT, axis=1)
    map_season = with_dummies_builder(Columns.SEASON, season_categorical_mapping)
    map_weather = with_dummies_builder(Columns.WEATHER, weather_categorical_mapping)
    return map_weather(map_season(with_day(bikeshares_without_unneeded_columns)))


def with_dummies_builder(categorical_column, category_mapping):
    return lambda bikeshares: with_dummy_variables(bikeshares, categorical_column, category_mapping)


def with_dummy_variables(bikeshares, categorical_column, category_mapping):
    seasons = pd.get_dummies(bikeshares.pop(categorical_column), drop_first=False)
    log_df(f"{categorical_column} before Renaming of Dummy Variables", seasons)
    seasons = seasons.rename(columns=category_mapping)
    log_df(f"{categorical_column} after Renaming of Dummy Variables", seasons)
    bikeshares_w_dummy_seasons = pd.concat([bikeshares, seasons], axis=1)
    return bikeshares_w_dummy_seasons


# # Utility Functions
# This function reads command line arguments, one of which can be the input loan data set
def parse_commandline_options(args):
    print(f"args are: {args}")
    loan_csv = f"{DEFAULT_DATASET_LOCATION}/{DEFAULT_BIKE_SHARE_CSV_FILENAME}"

    try:
        options, arguments = getopt.getopt(args, "i:hf:", ["input=", "help"])
        for option, argument in options:
            if option in ("-h", "--help"):
                print_help_text()
            elif option in ("-i", "--input"):
                loan_csv = argument
            else:
                print(f"{option} was not recognised as a valid option")
                print_help_text()
                print("Allowing to continue since Jupyter notebook passes in other command-line options")
        return loan_csv
    except getopt.GetoptError as e:
        sys.stderr.write("%s: %s\n" % (args[0], e.msg))
        print_help_text()
        exit(2)


# This function prints out the help text if either explicitly requested or in case of wrong input
def print_help_text():
    print("USAGE: python bike-sharing-main.py [{-i |--input=}<loan-csv>]")


# This function overrides Jupyter's default logger so that we can output things based on our formatting preferences
def setup_logging():
    warnings.filterwarnings("ignore")
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    logger = logging.getLogger()
    formatter = logging.Formatter('%(message)s')
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(formatter)
    logger.setLevel(logging.DEBUG)
    logger.addHandler(ch)


# This function reads the loan data set
def read_csv(csv):
    return pd.read_csv(csv, low_memory=False)


# This utility function pretty prints a heading for output
def heading(heading_text):
    logging.info("-" * 100)
    logging.info(heading_text)
    logging.info("-" * 100)


# This utility function pretty prints a dataframe for output
def log_df(dataframe_label, dataframe, num_rows=10):
    heading(dataframe_label)
    logging.info(dataframe.head(num_rows).to_string())


# # Main Entry Point: main()
# This function is the entry point of the script
def main():
    setup_logging()
    study(read_csv(parse_commandline_options(sys.argv[1:])))


main()
