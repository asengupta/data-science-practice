{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Running the file<br>\n", "If you wish to use your own copy of the data, use the following command:<br>\n", "<br>\n", "``python lending-club-main.py [{-i |--input=}<loan-csv>] [-h | --help]``<br>\n", "<br>\n", "Here are some examples:<br>\n", "<br>\n", "``python lending-club-main.py --input=loan.csv``<br>\n", "``python lending-club-main.py -i loan.csv``<br>\n", "``python lending-club-main.py``<br>\n", "``python lending-club-main.py --help``<br>\n", "<br>\n", "All of these arguments are optional. Providing no arguments makes the code read from the default location, i.e. ```./data```.<br>\n", "<br>\n", "# Instructions on regenerating this Jupyter Notebook<br>\n", "The Jupyter notebook can be regenerated by installing P2J, like so:<br>\n", "<br>\n", "``pip install p2j``<br>\n", "<br>\n", "and running the following:<br>\n", "<br>\n", "``p2j -o code/lending-club-main.py -t notebook/lending-club-main.ipynb``"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Library Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import getopt\n", "import logging\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Constants<br>\n", "A bunch of constants are set up so that strings don't clutter the source everywhere."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DEFAULT_DATASET_LOCATION = \"../data\"\n", "DEFAULT_LOAN_CSV_FILENAME = \"loan.csv\"\n", "ID = \"id\"\n", "MEMBER_ID = \"member_id\"\n", "DELINQUENT_2_YEARS = 'delinq_2yrs'\n", "EARLIER_CREDIT_LINE = 'earliest_cr_line'\n", "LAST_PAYMENT_AMOUNT = 'last_pymnt_amnt'\n", "LAST_CREDIT_PULL_DATE = 'last_credit_pull_d'\n", "APPLICATION_TYPE = 'application_type'\n", "LAST_PAYMENT_DATE = 'last_pymnt_d'\n", "COLLECTION_RECOVERY_FEE = 'collection_recovery_fee'\n", "RECOVERIES = 'recoveries'\n", "TOTAL_RECOVERED_LATE_FEE = 'total_rec_late_fee'\n", "TOTAL_PAYMENT = 'total_pymnt'\n", "TOTAL_PAYMENT_INVESTED = 'total_pymnt_inv'\n", "TOTAL_RECOVERED_PRINCIPAL = 'total_rec_prncp'\n", "OUT_PRINCIPAL_INVESTED = 'out_prncp_inv'\n", "OUT_PRINCIPAL = 'out_prncp'\n", "NUM_INQUIRIES_6_MONTHS = 'inq_last_6mths'\n", "NUM_OPRN_CREDIT_LINES = 'open_acc'\n", "NUM_DEROGATORY_PUBLIC_RECORDS = 'pub_rec'\n", "TOTAL_CREDOT_REVOLVING_BALANCE = 'revol_bal'\n", "REVOLVING_LINE_UTILISATION_RATE = 'revol_util'\n", "CURRENT_NUM_CREDIT_LINES = 'total_acc'\n", "INTEREST_RECEIVED_TILL_DATE = 'total_rec_int'\n", "PAYMENT_PLAN = 'pymnt_plan'\n", "INITIAL_LIST_STATUS = 'initial_list_status'\n", "POLICY_CODE = 'policy_code'\n", "URL = 'url'\n", "EMPLOYMENT_TITLE = 'emp_title'\n", "FUNDED_AMOUNT = 'funded_amnt'\n", "FUNDED_AMOUNT_INVESTED = 'funded_amnt_inv'\n", "INSTALLMENT = \"installment\"\n", "LOAN_STATUS = 'loan_status'\n", "INTEREST_RATE = 'int_rate'\n", "EMPLOYMENT_LENGTH = 'emp_length'\n", "ISSUE_DATE = 'issue_d'\n", "ISSUE_MONTH = 'issue_month'\n", "ISSUE_YEAR = 'issue_year'\n", "MONTHS_SINCE_LAST_DELINQUENCY = \"mths_since_last_delinq\"\n", "MONTHS_SINCE_LAST_RECORD = \"mths_since_last_record\"\n", "NEXT_PAYMENT_DATE = \"next_pymnt_d\"\n", "LOAN_AMOUNT = 'loan_amnt'\n", "TERM = 'term'\n", "INTEREST_RATE_CATEGORY = 'int_rate_cat'\n", "GRADE = 'grade'\n", "SUB_GRADE = 'sub_grade'\n", "HOME_OWNERSHIP = 'home_ownership'\n", "ANNUAL_INCOME = 'annual_inc'\n", "VERIFICATION_STATUS = 'verification_status'\n", "PURPOSE = 'purpose'\n", "ADDRESS_STATE = 'addr_state'\n", "DEBT_TO_INCOME_RATIO = 'dti'\n", "TAX_LIENS = 'tax_liens'\n", "DELINQ_AMNT = 'delinq_amnt'\n", "CHARGEOFF_WITHIN_12_MTHS = 'chargeoff_within_12_mths'\n", "ACC_NOW_DELINQ = 'acc_now_delinq'\n", "COLLECTIONS_12_MTHS_EX_MED = 'collections_12_mths_ex_med'\n", "FULLY_PAID = 'Fully Paid'\n", "CURRENT = 'Current'\n", "CHARGED_OFF = 'Charged Off'\n", "USELESS_COLUMNS = [TAX_LIENS, DELINQ_AMNT, CHARGEOFF_WITHIN_12_MTHS, ACC_NOW_DELINQ, COLLECTIONS_12_MTHS_EX_MED]\n", "CONSTANT_VALUED_COLUMNS = [PAYMENT_PLAN, INITIAL_LIST_STATUS, POLICY_CODE, EMPLOYMENT_TITLE, URL]\n", "CUSTOMER_BEHAVIOUR_COLUMNS = [DELINQUENT_2_YEARS, EARLIER_CREDIT_LINE, NUM_INQUIRIES_6_MONTHS, NUM_OPRN_CREDIT_LINES,\n", "                              NUM_DEROGATORY_PUBLIC_RECORDS,\n", "                              TOTAL_CREDOT_REVOLVING_BALANCE, REVOLVING_LINE_UTILISATION_RATE, CURRENT_NUM_CREDIT_LINES,\n", "                              OUT_PRINCIPAL, OUT_PRINCIPAL_INVESTED, TOTAL_PAYMENT, TOTAL_PAYMENT_INVESTED,\n", "                              TOTAL_RECOVERED_PRINCIPAL,\n", "                              INTEREST_RECEIVED_TILL_DATE, TOTAL_RECOVERED_LATE_FEE, RECOVERIES,\n", "                              COLLECTION_RECOVERY_FEE, LAST_PAYMENT_DATE,\n", "                              LAST_PAYMENT_AMOUNT, LAST_CREDIT_PULL_DATE, APPLICATION_TYPE,\n", "                              MONTHS_SINCE_LAST_DELINQUENCY, MONTHS_SINCE_LAST_RECORD, NEXT_PAYMENT_DATE]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Cleaning Loan Data<br>\n", "The cleanup consists of the following steps:<br>\n", "- Removing `desc` column<br>\n", "- Removing `member_id` column<br>\n", "- Removing completely null columns<br>\n", "- Removing customer behaviour columns which are not available for analysis for aspiring loan applicants<br>\n", "- Removing columns which have constant values and do not contribute to analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def non_null_loans(raw_loans):\n", "    ## Removing Desc column from dataset as it will be not helpful for us in this case study, whereas it can be helpful if we were solving NLP problem\n", "    loans_wo_desc = raw_loans.drop('desc', axis=1)\n", "    # Checking which column can be used as an identifier\n", "    heading(\"Check which column can be used as an identifier\")\n", "    verify_id_member_id_columns_are_not_correlated(loans_wo_desc)\n", "    loans_wo_desc_member_id = loans_wo_desc.drop(columns=[MEMBER_ID], axis=1)\n", "    # Both this column can be used as an identifier, anyone of these can be dropped. Also none of this is helpful for our analysis. They are just identifier\n", "    heading(\"Column Data Types\")\n", "    logging.debug(loans_wo_desc_member_id.dtypes)\n", "    loans_wo_nulls = clean_null_columns(loans_wo_desc_member_id)\n", "    heading(\"Loan Info after scrubbing completely empty columns\")\n", "    logging.debug(loans_wo_nulls.info())\n", "    loans_wo_nulls = clean_customer_behaviour_columns(loans_wo_nulls)\n", "    loans_wo_nulls = clean_constant_valued_columns(loans_wo_nulls)\n", "    loans_wo_nulls = clean_useless_columns(loans_wo_nulls)\n", "    return loans_wo_nulls"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Unindicative Columns Cleanup<br>\n", "These columns are not useful because they have values either 0 or Nan value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_useless_columns(loans):\n", "    logging.debug(loans[COLLECTIONS_12_MTHS_EX_MED].value_counts())\n", "    logging.debug(loans[ACC_NOW_DELINQ].value_counts())\n", "    logging.debug(loans[CHARGEOFF_WITHIN_12_MTHS].value_counts())\n", "    logging.debug(loans[DELINQ_AMNT].value_counts())\n", "    logging.debug(loans[TAX_LIENS].value_counts())\n", "    return loans.drop(columns=USELESS_COLUMNS, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Null Column Cleanup<br>\n", "The loan dataset has several columns which are completely empty. These are useless for analysis.<br>\n", "This function drops completely null columns."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_null_columns(loans):\n", "    heading(\"Null Entries Statistics\")\n", "    null_entry_statistics = loans.isnull().sum() / len(loans.index)\n", "    null_columns = null_entry_statistics[null_entry_statistics == 1.0].index.to_numpy()\n", "    heading(\"Completely Null Columns\")\n", "    logging.info(null_columns)\n", "    return loans.drop(null_columns, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Verifying that member_id's and id's are completely unique from each other"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def verify_id_member_id_columns_are_not_correlated(loans):\n", "    ids_as_number = pd.to_numeric(loans[ID])\n", "    member_ids_as_number = pd.to_numeric(loans[MEMBER_ID])\n", "    logging.info(f\"Unique entries in id column : {ids_as_number.nunique()}\")\n", "    logging.info(f\"Unique entries in member_id column : {member_ids_as_number.nunique()}\")\n", "    ids_not_in_member_ids = set(ids_as_number).difference(set(member_ids_as_number))\n", "    member_ids_not_in_ids = set(member_ids_as_number).difference(set(ids_as_number))\n", "    logging.info(f\"id's not in member_id's = {len(ids_not_in_member_ids)}\")\n", "    logging.info(f\"member_id's not in id's = {len(member_ids_not_in_ids)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Dropping Customer Behaviour Columns<br>\n", "Removing columns  which are customer behaviour variable. This values will not be available to us while customer is filling the loan form.<br>\n", "Hence this will be not helpful for deciding whether customer will charged off or full pay"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_customer_behaviour_columns(loans_wo_nulls):\n", "    return loans_wo_nulls.drop(columns=CUSTOMER_BEHAVIOUR_COLUMNS, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Constant-Valued Columns<br>\n", "There are a few columns which have constant values. Such as pymnt_plan,initial_list_status,policy_code. We can drop these. Along with this, we can also drop<br>\n", "emp_title and URL column because they too don't contain values which can help do decide loan_status"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_constant_valued_columns(loans_wo_nulls):\n", "    logging.info(f\"Unique Values in column pymnt_plan: {loans_wo_nulls[PAYMENT_PLAN].nunique()}\")\n", "    logging.info(f\"Unique Values in column initial_list_status: {loans_wo_nulls[INITIAL_LIST_STATUS].nunique()}\")\n", "    logging.info(f\"Unique Values in column policy_code: {loans_wo_nulls[POLICY_CODE].nunique()}\")\n", "    return loans_wo_nulls.drop(columns=CONSTANT_VALUED_COLUMNS, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Checking Correlation between columns<br>\n", "We check the correlation between pairs of columns, this gives us a statistic (the default being the Pearson correlation coefficient).<br>\n", "The correlation coefficient gives a measure of how one factor varies with the other."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def multicollinear_free_loads(loans):\n", "    heading(\"Check for Highly Correlated variables\")\n", "    correlations = loans.corr()\n", "    indexes = correlations.index.to_numpy()\n", "    heading(\"Correlation Coefficients\")\n", "    logging.info(correlations.to_string())\n", "    heading(\"Highly Correlated Columns\")\n", "    for row in indexes:\n", "        for col in indexes:\n", "            if (row == col):\n", "                continue\n", "            if (correlations[row][col] >= 0.85):\n", "                logging.info(f\"[{row},{col}] = {correlations[row][col]}\")\n\n", "    # loan_amnt, funded_amnt and funded_amnt_inv have high correlation. High correlation means they all contains the same information. We can drop 2 out of 3.\n", "    # we will keep loan_amnt and rest 2 can be dropped.\n", "    # installment is also highly correlated\n", "    return loans.drop(columns=[FUNDED_AMOUNT, FUNDED_AMOUNT_INVESTED], axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Remove loans which are of status CURRENT<br>\n", "Loans with `CURRENT` status are current customers involved in paying off their loans.<br>\n", "These loans do not provide us with any training information from which we can infer any conclusions."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def loans_without_current_loans(loans):\n", "    heading(\"Loan Statuses: There should only be 3 categories\")\n", "    logging.info(loans[LOAN_STATUS].value_counts())\n", "    print(\"Shape of the data before dropping rows\", loans.shape)\n", "    loans_wo_current = loans[loans[LOAN_STATUS] != CURRENT]\n", "    print(\"Shape of the data after dropping rows\", loans_wo_current.shape)\n", "    return loans_wo_current"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Recheck Null Values after Cleanup<br>\n", "We still have null values in the data. We can fill those values. But EDA doesn't require to fill. Handling missing value is part of modelling."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def recheck_null_values(loans_with_corrected_data_types):\n", "    heading(\"Null value checks after Cleanup\")\n", "    logging.info(loans_with_corrected_data_types.isnull().sum())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Correction of Data Types<br>\n", "Some columns needed for numerical EDA do not show up as numbers, or properly-formatted dates.<br>\n", "Examples are: for `interest rate`, `employment length` and `issue date`. We fix these factors here."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def corrected_data_types(loans):\n", "    loans = loans.copy()\n", "    loans[INTEREST_RATE] = loans[INTEREST_RATE].apply(lambda x: float(str(x).replace('%', '')))\n", "    loans[EMPLOYMENT_LENGTH] = loans[EMPLOYMENT_LENGTH].apply(\n", "        lambda x: float(str(x).replace('years', '').replace('year', '').replace('+', '').replace('< 1', '0.5')))\n", "    loans[ISSUE_DATE] = pd.to_datetime(loans[ISSUE_DATE], format='%b-%y')\n", "    loans[ISSUE_MONTH] = pd.DatetimeIndex(loans[ISSUE_DATE]).month\n", "    loans[ISSUE_YEAR] = pd.DatetimeIndex(loans[ISSUE_DATE]).year\n", "    return loans"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Univariate (Unsegmented) Analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyse_univariate_unsegmented(loans):\n", "    plot_loan_amount_distribution_univariate(loans)\n", "    plot_loan_requests_by_month_univariate(loans)\n", "    plot_loan_requests_by_year_univariate(loans)\n", "    plot_term_counts_univariate(loans)\n", "    plot_interest_rate_distribution_univariate(loans)\n", "    plot_loan_grade_distribution_univariate(loans)\n", "    plot_loan_sub_grade_distribution_univariate(loans)\n", "    plot_employment_length_distribution_univariate(loans)\n", "    plot_home_ownership_distributions_univariate(loans)\n", "    plot_annual_income_distribution_univariate(loans)\n", "    plot_verification_status_distribution_univariate(loans)\n", "    plot_loan_purpose_distribution_univariate(loans)\n", "    plot_address_state_distribution_univariate(loans)\n", "    plot_dti_distribution_univariate(loans)\n", "    loans[DEBT_TO_INCOME_RATIO].describe()\n", "    ### Higher the DTI, higher % of monthly income is paid towards EMI\n", "    loans['pub_rec_bankruptcies'].value_counts().plot.barh()\n", "    plt.title(\"Filed Public Bankruptcies\")\n", "    plt.xlabel(\"Count\")\n", "    plt.ylabel(\"Number of Filing\")\n", "    plt.show()\n", "    #### Very Few Appliant have filed for bankruptcies"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Segmented Univariate Analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyse_univariate_segmented(loans):\n", "    plot_pi_overall_charged_off_vs_paid(loans)\n", "    plot_loan_amount_across_time_by_loan_status(loans)\n", "    for i in loans.select_dtypes(include=['int', 'float']).columns:\n", "        sns.boxplot(data=loans, x=LOAN_STATUS, y=i)\n", "        plt.title(\"Loan Status vs \" + i)\n", "        plt.show()\n", "    plot_requested_loan_amount_by_loan_status(loans)\n", "    plot_users_term_by_loan_status(loans)\n", "    loans[INTEREST_RATE_CATEGORY] = pd.cut(loans[INTEREST_RATE], 4, labels=[\"low\", \"med\", \"high\", \"vhigh\"])\n", "    logging.info(pd.cut(loans[INTEREST_RATE], 4, ).value_counts())\n", "    plot_users_loan_category_by_loan_status(loans)\n", "    plot_installment_by_loan_status(loans)\n", "    loans.groupby(by=[GRADE])[LOAN_STATUS].value_counts().unstack().apply(lambda x: x / sum(x), axis=1).plot(kind='bar',\n", "                                                                                                             stacked=True)\n", "    plot_sub_grade_by_loan_status(loans)\n", "    plot_employment_length_by_loan_status(loans)\n", "    plot_home_ownership_by_loan_status(loans)\n", "    plot_annual_income_by_loan_status(loans)\n", "    logging.info(loans[ANNUAL_INCOME].describe().apply(lambda x: '%.5f' % x))\n", "    plot_restricted_annual_income_by_loan_status(loans)\n", "    plot_verification_status_by_loan_status(loans)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Bivariate Analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyse_bivariate(loans):\n", "    logging.info(loans.groupby(by=LOAN_STATUS)[LOAN_AMOUNT].describe())\n", "    #### Mean is higher in both the cases of loan_status with respect to median, this show right skew data\n", "    #### The user who is defaulter ask for higher loan amount compared to Non-Defaulter\n", "    pair_plot_across_all_attributes(loans)\n", "    plot_verification_status_for_independent_loan_statuses(loans)\n", "    plot_grade_subgrade_heatmap_by_loan_status(loans)\n", "    plot_yearly_monthly_by_loan_status(loans)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Analysis Entry Point"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyse(loans):\n", "    analyse_univariate_unsegmented(loans)\n", "    analyse_univariate_segmented(loans)\n", "    analyse_bivariate(loans)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# EDA Plot Functions<br>\n", "This section contains all the plot functions used in Univariate (Segmented and Unsegmented) and Bivariate EDA"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_dti_distribution_univariate(loans):\n", "    sns.displot(data=loans, x=DEBT_TO_INCOME_RATIO)\n", "    plt.title(\"Distribution of Debt to Income Ratio\")\n", "    plt.show()\n", "    ### Data seems to be normally distributed, Median and mean is almost eqauls"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_address_state_distribution_univariate(loans):\n", "    plt.figure(figsize=(10, 5))\n", "    sns.barplot(data=loans[ADDRESS_STATE].value_counts().reset_index(), x='index', y='addr_state', )\n", "    plt.title(\"States of the Applicant\")\n", "    plt.xlabel(\"States\")\n", "    plt.ylabel(\"Count\")\n", "    plt.xticks(rotation=90)\n", "    plt.show()\n", "    ### Highest Applicant are from CA,NY and lowest from NE,ME"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loan_purpose_distribution_univariate(loans):\n", "    plt.figure(figsize=(10, 5))\n", "    sns.barplot(data=loans[PURPOSE].value_counts().reset_index(), x='index', y=\"purpose\", estimator=lambda x: np.sum(x))\n", "    plt.title(\"Purpose of the Loan\")\n", "    plt.xticks(rotation=90)\n", "    plt.xlabel(\"Purpose\")\n", "    plt.ylabel(\"Count\")\n", "    plt.show()\n", "    ### Applicant is taking a loan for Debt_Consolidation, Credit Card"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_verification_status_distribution_univariate(loans):\n", "    loans[VERIFICATION_STATUS].value_counts(1).plot.pie(autopct='%1.1f%%')\n", "    plt.title(\"Income Verification of the Loan Applicant\")\n", "    plt.show()\n", "    #### 43% of applicant's income source wasn't verified"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_annual_income_distribution_univariate(loans):\n", "    pd.options.display.float_format = '{:.2f}'.format\n", "    sns.histplot(data=loans, x=ANNUAL_INCOME, kde=True)\n", "    plt.title(\"Annual Income of the Applicant\")\n", "    plt.show()\n", "    #### Data is Right Skew.\n", "    logging.info(loans[ANNUAL_INCOME].describe())\n", "    ## Average Income is greater than Median Income. Income ranges from 4,000 to 6,00,000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_home_ownership_distributions_univariate(loans):\n", "    loans['home_ownership'].value_counts().plot.barh()\n", "    plt.title(\"Home Ownership\")\n", "    plt.show()\n", "    #### Applicants is living either on Rent or on Mortgage propoerty"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_employment_length_distribution_univariate(loans):\n", "    loans[EMPLOYMENT_LENGTH].value_counts().plot.bar()\n", "    plt.title(\"Employment Length\")\n", "    plt.xlabel(\"Years of experience\")\n", "    plt.ylabel(\"Count of Applicant\")\n", "    plt.show()\n", "    ### Most of the Applicant have 10Years of experience"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loan_sub_grade_distribution_univariate(loans):\n", "    loans[SUB_GRADE].value_counts().plot.bar(title='Sub Grade Frequency');\n", "    plt.xlabel(\"Sub Grade\")\n", "    plt.ylabel(\"Count\")\n", "    plt.show()\n", "    #### Many Users have been assigned with A4 grade, few people have been assigned with G5 grade\n", "    ### B3 garde is the highest in B grade"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loan_grade_distribution_univariate(loans):\n", "    loans[GRADE].value_counts().plot.bar(title='Grade Frequency');\n", "    plt.xlabel(\"Grade\")\n", "    plt.ylabel(\"Count\")\n", "    plt.show()\n", "    #### More Users have been assigned B grade, few people have been assigned with G grade"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_interest_rate_distribution_univariate(loans):\n", "    sns.displot(data=loans, x=INTEREST_RATE, kind='hist', color='blue')\n", "    plt.title(\"Distribution of Interest Rate\")\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_term_counts_univariate(loans):\n", "    loans[TERM].value_counts(1).plot.pie();\n", "    ### Most of the users have taken a loan for shorter period i.e. 36 month compared to 60 months"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loan_requests_by_year_univariate(loans):\n", "    loans[ISSUE_YEAR].value_counts().plot.line();\n", "    plt.title(\"Year & Loan Request\")\n", "    plt.xlabel(\"Year\")\n", "    plt.ylabel(\"Count\")\n", "    plt.show()\n", "    #### We are seeing number of loan request increasing year over year. Exponentiat growth can be seen\n", "    ### In 2011 we see highest number of loan request"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loan_requests_by_month_univariate(loans):\n", "    loans[ISSUE_MONTH].value_counts().plot.line();\n", "    plt.title(\"Month & Loan Request\")\n", "    plt.xlabel(\"Month\")\n", "    plt.ylabel(\"Count\")\n", "    plt.show()\n", "    #### We are seeing number of loan request increasing as month passes.\n", "    ### In Dec we see highest number of loan request, lowest in Feb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loan_amount_distribution_univariate(loans):\n", "    # Distribution of loan amount\n", "    plt.figure(figsize=(10, 5))\n", "    sns.histplot(data=loans, x=LOAN_AMOUNT, kde=True)\n", "    plt.title(\"Distribution of Loan Amount\")\n", "    plt.show()\n", "    #### More numbers of loan were taken for amount 5000-1000. We see spike at multiples of 5000 i.e. 5000,10000,15000 etc"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_sub_grade_by_loan_status(loans):\n", "    plt.figure(figsize=(10, 6))\n", "    loans.groupby(by=[SUB_GRADE])[LOAN_STATUS].value_counts().unstack().apply(lambda x: x / sum(x), axis=1).plot(\n", "        kind='bar', stacked=True);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_verification_status_by_loan_status(loans):\n", "    loans.groupby(by=[VERIFICATION_STATUS, LOAN_STATUS])[LOAN_STATUS].count().unstack().fillna(0).plot.bar()\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_restricted_annual_income_by_loan_status(loans):\n", "    sns.boxplot(data=loans[(loans[ANNUAL_INCOME] > 10000) & (loans[ANNUAL_INCOME] < 100000)], y=ANNUAL_INCOME,\n", "                x=LOAN_STATUS)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_annual_income_by_loan_status(loans):\n", "    sns.boxplot(data=loans, y=ANNUAL_INCOME, x=LOAN_STATUS)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_home_ownership_by_loan_status(loans):\n", "    loans.groupby(by=[HOME_OWNERSHIP, LOAN_STATUS])[LOAN_STATUS].count().unstack().fillna(0).plot.bar()\n", "    plt.title(\"Home Ownership\")\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_employment_length_by_loan_status(loans):\n", "    sns.histplot(data=loans, x=EMPLOYMENT_LENGTH, hue=LOAN_STATUS, multiple='stack');"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_installment_by_loan_status(loans):\n", "    plt.figure(figsize=(10, 5))\n", "    plt.subplot(1, 2, 1)\n", "    sns.histplot(data=loans[loans[LOAN_STATUS] == FULLY_PAID], x=INSTALLMENT)\n", "    plt.subplot(1, 2, 2)\n", "    sns.histplot(data=loans[loans[LOAN_STATUS] != FULLY_PAID], x=INSTALLMENT, color='r')\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_users_loan_category_by_loan_status(loans):\n", "    loans.groupby(by=[INTEREST_RATE_CATEGORY, LOAN_STATUS])[LOAN_STATUS].count().unstack().apply(\n", "        lambda x: x / sum(x),\n", "        axis=1).plot(\n", "        kind='bar', stacked=True)\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_requested_loan_amount_by_loan_status(loans):\n", "    plt.figure(figsize=(10, 5))\n", "    sns.histplot(data=loans, x=LOAN_AMOUNT, hue=LOAN_STATUS, binwidth=1000, multiple=\"stack\")\n", "    plt.title(\"Loan Amount Requested Distribution\")\n", "    plt.xlabel(\"Loan Amount Requested\")\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_users_term_by_loan_status(loans):\n", "    plt.figure(figsize=(10, 8))\n", "    loans.groupby(by=[TERM, LOAN_STATUS])[LOAN_STATUS].count().unstack().apply(lambda x: x / sum(x), axis=1).plot(\n", "        kind='bar', stacked=True)\n", "    plt.title(\"Distribution of users for loan term\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loan_amount_across_time_by_loan_status(loans):\n", "    plt.figure(figsize=(20, 10))\n", "    sns.lineplot(data=loans, x=ISSUE_DATE, y=LOAN_AMOUNT, hue=LOAN_STATUS)\n", "    plt.title(\"Loan Given across the date\")\n", "    plt.xticks(rotation=90)\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_pi_overall_charged_off_vs_paid(loans):\n", "    plt.pie(loans[LOAN_STATUS].value_counts(1), labels=loans[LOAN_STATUS].value_counts(1).index.to_list(),\n", "            explode=[0.1, 0.1], shadow=True, autopct='%.2f%%')\n", "    plt.title(\"% of Users\")\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_verification_status_for_independent_loan_statuses(loans):\n", "    loan_status_by_verification_status = round(\n", "        loans.groupby(by=[LOAN_STATUS, VERIFICATION_STATUS])[LOAN_STATUS].count().unstack().apply(lambda x: x / sum(x),\n", "                                                                                                  axis=1) * 100, 2)\n", "    heading(\"Loan Status vs. Verification Status Statistics\")\n", "    logging.info(loan_status_by_verification_status)\n", "    round(\n", "        loans.groupby(by=[LOAN_STATUS, VERIFICATION_STATUS])[LOAN_STATUS].count().unstack().apply(lambda x: x / sum(x),\n", "                                                                                                  axis=1) * 100,\n", "        2).plot.barh(figsize=(10, 10))\n", "    ##### Verified user are getting more default\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_grade_subgrade_heatmap_by_loan_status(loans):\n", "    loans[LOAN_STATUS] = np.where(loans[LOAN_STATUS] == CHARGED_OFF, 1, 0)\n", "    plt.figure(figsize=(10, 8))\n", "    sns.heatmap(data=loans.groupby(by=[GRADE, SUB_GRADE])[LOAN_STATUS].mean().unstack().fillna(-1), cmap='Reds')\n", "    plt.show()\n", "    #### Users who get F5 subgrade defaults more followed by G3"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_yearly_monthly_by_loan_status(loans):\n", "    loans.groupby(by=[ISSUE_YEAR, ISSUE_MONTH])[LOAN_STATUS].sum().plot.bar(figsize=(20, 5),\n", "                                                                            title=\"Number of Defaulters YoY\")\n", "    plt.xlabel(\"Issue Year & Month\")\n", "    plt.ylabel(\"Defaulter Count\")\n", "    plt.show()\n", "    ### Defaulters are increasing every year, though we have seen financial crisis in 2008, but they didn't defaulted much"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pair_plot_across_all_attributes(loans):\n", "    sns.pairplot(data=loans)\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Entry Point for CRISPR<br>\n", " This function is the entry point for the entire CRISPR process. This is called by `main()`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def study(raw_loans):\n", "    logging.debug(raw_loans.head().to_string())\n", "    # Number of Rows and Columns in the data set\n", "    logging.debug(raw_loans.shape)\n", "    logging.debug(raw_loans.columns)\n", "    loans_wo_unneeded_columns = non_null_loans(raw_loans)\n", "    loans_wo_correlated_factors = multicollinear_free_loads(loans_wo_unneeded_columns)\n", "    loans_wo_current = loans_without_current_loans(loans_wo_correlated_factors)\n", "    loans_with_corrected_data_types = corrected_data_types(loans_wo_current)\n", "    recheck_null_values(loans_with_corrected_data_types)\n", "    loans_with_corrected_data_types.set_index(keys=ID, inplace=True)\n", "    analyse(loans_with_corrected_data_types)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Utility Functions<br>\n", "This function reads command line arguments, one of which can be the input loan data set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_commandline_options(args):\n", "    print(f\"args are: {args}\")\n", "    loan_csv = f\"{DEFAULT_DATASET_LOCATION}/{DEFAULT_LOAN_CSV_FILENAME}\"\n", "    try:\n", "        options, arguments = getopt.getopt(args, \"i:hf:\", [\"input=\", \"help\"])\n", "        for option, argument in options:\n", "            if option in (\"-h\", \"--help\"):\n", "                print_help_text()\n", "            elif option in (\"-i\", \"--input\"):\n", "                loan_csv = argument\n", "            else:\n", "                print(f\"{option} was not recognised as a valid option\")\n", "                print_help_text()\n", "                print(\"Allowing to continue since Jupyter notebook passes in other command-line options\")\n", "        return loan_csv\n", "    except getopt.GetoptError as e:\n", "        sys.stderr.write(\"%s: %s\\n\" % (args[0], e.msg))\n", "        print_help_text()\n", "        exit(2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This function prints out the help text if either explicitly requested or in case of wrong input"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def print_help_text():\n", "    print(\"USAGE: python lending-club-main.py [{-i |--input=}<loan-csv>]\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This function overrides Jupyter's default logger so that we can output things based on our formatting preferences"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def setup_logging():\n", "    for handler in logging.root.handlers[:]:\n", "        logging.root.removeHandler(handler)\n", "    logger = logging.getLogger()\n", "    formatter = logging.Formatter('%(message)s')\n", "    ch = logging.StreamHandler()\n", "    ch.setLevel(logging.DEBUG)\n", "    ch.setFormatter(formatter)\n", "    logger.setLevel(logging.DEBUG)\n", "    logger.addHandler(ch)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This function reads the loan data set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_csv(loan_csv):\n", "    return pd.read_csv(loan_csv, low_memory=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This utility function pretty prints a heading for output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def heading(heading_text):\n", "    logging.info(\"-\" * 100)\n", "    logging.info(heading_text)\n", "    logging.info(\"-\" * 100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Main Entry Point: main()<br>\n", "This function is the entry point of the script"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    setup_logging()\n", "    study(read_csv(parse_commandline_options(sys.argv[1:])))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}