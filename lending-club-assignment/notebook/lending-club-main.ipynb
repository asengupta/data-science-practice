{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Running the file<br>\n", "If you wish to use your own copy of the data, use the following command:<br>\n", "<br>\n", "``python lending-club-main.py [{-i |--input=}<loan-csv>] [-h | --help]``<br>\n", "<br>\n", "Here are some examples:<br>\n", "<br>\n", "``python lending-club-main.py --input=loan.csv``<br>\n", "``python lending-club-main.py -i loan.csv``<br>\n", "``python lending-club-main.py``<br>\n", "``python lending-club-main.py --help``<br>\n", "<br>\n", "All of these arguments are optional. Providing no arguments makes the code read from the default location, i.e. ```./data```.<br>\n", "<br>\n", "# Instructions on regenerating this Jupyter Notebook<br>\n", "The Jupyter notebook can be regenerated by installing P2J, like so:<br>\n", "<br>\n", "``pip install p2j``<br>\n", "<br>\n", "and running the following:<br>\n", "<br>\n", "``p2j -o code/lending-club-main.py -t notebook/lending-club-main.ipynb``"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import getopt\n", "import logging\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A bunch of constants are set up so that strings don't clutter the source everywhere."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DEFAULT_DATASET_LOCATION = \"../data\"\n", "DEFAULT_LOAN_CSV_FILENAME = \"loan.csv\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ID = \"id\"\n", "MEMBER_ID = \"member_id\"\n", "DELINQUENT_2_YEARS = 'delinq_2yrs'\n", "EARLIER_CREDIT_LINE = 'earliest_cr_line'\n", "LAST_PAYMENT_AMOUNT = 'last_pymnt_amnt'\n", "LAST_CREDIT_PULL_DATE = 'last_credit_pull_d'\n", "APPLICATION_TYPE = 'application_type'\n", "LAST_PAYMENT_DATE = 'last_pymnt_d'\n", "COLLECTION_RECOVERY_FEE = 'collection_recovery_fee'\n", "RECOVERIES = 'recoveries'\n", "TOTAL_RECOVERED_LATE_FEE = 'total_rec_late_fee'\n", "TOTAL_PAYMENT = 'total_pymnt'\n", "TOTAL_PAYMENT_INVESTED = 'total_pymnt_inv'\n", "TOTAL_RECOVERED_PRINCIPAL = 'total_rec_prncp'\n", "OUT_PRINCIPAL_INVESTED = 'out_prncp_inv'\n", "OUT_PRINCIPAL = 'out_prncp'\n", "NUM_INQUIRIES_6_MONTHS = 'inq_last_6mths'\n", "NUM_OPRN_CREDIT_LINES = 'open_acc'\n", "NUM_DEROGATORY_PUBLIC_RECORDS = 'pub_rec'\n", "TOTAL_CREDOT_REVOLVING_BALANCE = 'revol_bal'\n", "REVOLVING_LINE_UTILISATION_RATE = 'revol_util'\n", "CURRENT_NUM_CREDIT_LINES = 'total_acc'\n", "INTEREST_RECEIVED_TILL_DATE = 'total_rec_int'\n", "PAYMENT_PLAN = 'pymnt_plan'\n", "INITIAL_LIST_STATUS = 'initial_list_status'\n", "POLICY_CODE = 'policy_code'\n", "URL = 'url'\n", "EMPLOYMENT_TITLE = 'emp_title'\n", "FUNDED_AMOUNT = 'funded_amnt'\n", "FUNDED_AMOUNT_INVESTED = 'funded_amnt_inv'\n", "INSTALLMENT = \"installment\"\n", "LOAN_STATUS = 'loan_status'\n", "INTEREST_RATE = 'int_rate'\n", "EMPLOYMENT_LENGTH = 'emp_length'\n", "ISSUE_DATE = 'issue_d'\n", "ISSUE_MONTH = 'issue_month'\n", "ISSUE_YEAR = 'issue_year'\n", "MONTHS_SINCE_LAST_DELINQUENCY = \"mths_since_last_delinq\"\n", "MONTHS_SINCE_LAST_RECORD = \"mths_since_last_record\"\n", "NEXT_PAYMENT_DATE = \"next_pymnt_d\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CURRENT = 'Current'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CONSTANT_VALUED_COLUMNS = [PAYMENT_PLAN, INITIAL_LIST_STATUS, POLICY_CODE, EMPLOYMENT_TITLE, URL]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CUSTOMER_BEHAVIOUR_COLUMNS = [DELINQUENT_2_YEARS, EARLIER_CREDIT_LINE, NUM_INQUIRIES_6_MONTHS, NUM_OPRN_CREDIT_LINES,\n", "                              NUM_DEROGATORY_PUBLIC_RECORDS,\n", "                              TOTAL_CREDOT_REVOLVING_BALANCE, REVOLVING_LINE_UTILISATION_RATE, CURRENT_NUM_CREDIT_LINES,\n", "                              OUT_PRINCIPAL, OUT_PRINCIPAL_INVESTED, TOTAL_PAYMENT, TOTAL_PAYMENT_INVESTED,\n", "                              TOTAL_RECOVERED_PRINCIPAL,\n", "                              INTEREST_RECEIVED_TILL_DATE, TOTAL_RECOVERED_LATE_FEE, RECOVERIES,\n", "                              COLLECTION_RECOVERY_FEE, LAST_PAYMENT_DATE,\n", "                              LAST_PAYMENT_AMOUNT, LAST_CREDIT_PULL_DATE, APPLICATION_TYPE,\n", "                              MONTHS_SINCE_LAST_DELINQUENCY, MONTHS_SINCE_LAST_RECORD, NEXT_PAYMENT_DATE]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cleaning Completely Null Columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_null_columns(loans):\n", "    heading(\"Null Entries Statistics\")\n", "    null_entry_statistics = loans.isnull().sum() / len(loans.index)\n", "    null_columns = null_entry_statistics[null_entry_statistics == 1.0].index.to_numpy()\n", "    heading(\"Completely Null Columns\")\n", "    logging.info(null_columns)\n", "    return loans.drop(null_columns, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Cleaning Loan Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def cleaned_loans(raw_loans):\n", "    ## Removing Desc column from dataset as it will be not helpful for us in this case study, whereas it can be helpful if we were solving NLP problem\n", "    loans_wo_desc = raw_loans.drop('desc', axis=1)\n", "    # Checking which column can be used as an identifier\n", "    heading(\"Check which column can be used as an identifier\")\n", "    verify_id_member_id_columns_are_not_correlated(loans_wo_desc)\n", "    loans_wo_desc_member_id = loans_wo_desc.drop(columns=[MEMBER_ID], axis=1)\n", "    # Both this column can be used as an identifier, anyone of these can be dropped. Also none of this is helpful for our analysis. They are just identifier\n", "    heading(\"Column Data Types\")\n", "    logging.debug(loans_wo_desc_member_id.dtypes)\n", "    loans_wo_nulls = clean_null_columns(loans_wo_desc_member_id)\n", "    heading(\"Loan Info after scrubbing completely empty columns\")\n", "    logging.debug(loans_wo_nulls.info())\n", "    loans_wo_nulls = clean_customer_behaviour_columns(loans_wo_nulls)\n", "    loans_wo_nulls = clean_constant_valued_columns(loans_wo_nulls)\n", "    return loans_wo_nulls"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Verifying that member_id's and id's are completely unique from each other"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def verify_id_member_id_columns_are_not_correlated(loans):\n", "    ids_as_number = pd.to_numeric(loans[ID])\n", "    member_ids_as_number = pd.to_numeric(loans[MEMBER_ID])\n", "    logging.info(f\"Unique entries in id column : {ids_as_number.nunique()}\")\n", "    logging.info(f\"Unique entries in member_id column : {member_ids_as_number.nunique()}\")\n", "    ids_not_in_member_ids = set(ids_as_number).difference(set(member_ids_as_number))\n", "    member_ids_not_in_ids = set(member_ids_as_number).difference(set(ids_as_number))\n", "    logging.info(f\"id's not in member_id's = {len(ids_not_in_member_ids)}\")\n", "    logging.info(f\"member_id's not in id's = {len(member_ids_not_in_ids)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Removing columns  which are customer behaviour variable. This values will not be available to us while customer is filling the loan form.<br>\n", "Hence this will be not helpful for deciding whether customer will charged off or full pay"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_customer_behaviour_columns(loans_wo_nulls):\n", "    return loans_wo_nulls.drop(columns=CUSTOMER_BEHAVIOUR_COLUMNS, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["There are a few columns which have constant values. Such as pymnt_plan,initial_list_status,policy_code. We can drop these. Along with this, we can also drop<br>\n", "emp_title and URL column because they too don't contain values which can help do decide loan_status"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_constant_valued_columns(loans_wo_nulls):\n", "    logging.info(f\"Unique Values in column pymnt_plan: {loans_wo_nulls[PAYMENT_PLAN].nunique()}\")\n", "    logging.info(f\"Unique Values in column initial_list_status: {loans_wo_nulls[INITIAL_LIST_STATUS].nunique()}\")\n", "    logging.info(f\"Unique Values in column policy_code: {loans_wo_nulls[POLICY_CODE].nunique()}\")\n", "    return loans_wo_nulls.drop(columns=CONSTANT_VALUED_COLUMNS, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Checking Correlation between columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def multicollinear_free_loads(loans):\n", "    heading(\"Check for Highly Correlated variables\")\n", "    correlations = loans.corr()\n", "    indexes = correlations.index.to_numpy()\n", "    heading(\"Correlation Coefficients\")\n", "    logging.info(correlations.to_string())\n", "    heading(\"Highly Correlated Columns\")\n", "    for row in indexes:\n", "        for col in indexes:\n", "            if (row == col):\n", "                continue\n", "            if (correlations[row][col] >= 0.85):\n", "                logging.info(f\"[{row},{col}] = {correlations[row][col]}\")\n\n", "    # loan_amnt, funded_amnt and funded_amnt_inv have high correlation. High correlation means they all contains the same information. We can drop 2 out of 3.\n", "    # we will keep loan_amnt and rest 2 can be dropped.\n", "    # installment is also highly correlated\n", "    return loans.drop(columns=[FUNDED_AMOUNT, FUNDED_AMOUNT_INVESTED, INSTALLMENT], axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Remove loans which are of status CURRENT"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def loans_without_current_loans(loans):\n", "    heading(\"Loan Statuses: There should only be 3 categories\")\n", "    logging.info(loans[LOAN_STATUS].value_counts())\n", "    print(\"Shape of the data before dropping rows\", loans.shape)\n", "    loans_wo_current = loans[loans[LOAN_STATUS] != CURRENT]\n", "    print(\"Shape of the data after dropping rows\", loans_wo_current.shape)\n", "    return loans_wo_current"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Correct data types for interest rate, employment length and issue date"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def corrected_data_types(loans):\n", "    loans = loans.copy()\n", "    loans[INTEREST_RATE] = loans[INTEREST_RATE].apply(lambda x: float(str(x).replace('%', '')))\n", "    loans[EMPLOYMENT_LENGTH] = loans[EMPLOYMENT_LENGTH].apply(\n", "        lambda x: float(str(x).replace('years', '').replace('year', '').replace('+', '').replace('< 1', '0.5')))\n", "    loans[ISSUE_DATE] = pd.to_datetime(loans[ISSUE_DATE], format='%b-%y')\n", "    loans[ISSUE_MONTH] = pd.DatetimeIndex(loans[ISSUE_DATE]).month\n", "    loans[ISSUE_YEAR] = pd.DatetimeIndex(loans[ISSUE_DATE]).year\n", "    return loans"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyse(raw_loans):\n", "    logging.debug(raw_loans.head().to_string())\n", "    # Number of Rows and Columns in the data set\n", "    logging.debug(raw_loans.shape)\n", "    logging.debug(raw_loans.columns)\n", "    loans_wo_unneeded_columns = cleaned_loans(raw_loans)\n", "    loans_wo_correlated_factors = multicollinear_free_loads(loans_wo_unneeded_columns)\n", "    loans_wo_current = loans_without_current_loans(loans_wo_correlated_factors)\n", "    loans_with_corrected_data_types = corrected_data_types(loans_wo_current)\n", "    recheck_null_values(loans_with_corrected_data_types)\n", "    loans_with_corrected_data_types.set_index(keys=ID, inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Recheck Null Values after Cleanup<br>\n", "We still have null values in the data. We can fill those values. But EDA doesn't require to fill. Handling missing value is part of modelling."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def recheck_null_values(loans_with_corrected_data_types):\n", "    heading(\"Null value checks after Cleanup\")\n", "    logging.info(loans_with_corrected_data_types.isnull().sum())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This function reads the loan data set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_commandline_options(args):\n", "    print(f\"args are: {args}\")\n", "    loan_csv = f\"{DEFAULT_DATASET_LOCATION}/{DEFAULT_LOAN_CSV_FILENAME}\"\n", "    try:\n", "        options, arguments = getopt.getopt(args, \"i:hf:\", [\"input=\", \"help\"])\n", "        for option, argument in options:\n", "            if option in (\"-h\", \"--help\"):\n", "                print_help_text()\n", "            elif option in (\"-i\", \"--input\"):\n", "                loan_csv = argument\n", "            else:\n", "                print(f\"{option} was not recognised as a valid option\")\n", "                print_help_text()\n", "                print(\"Allowing to continue since Jupyter notebook passes in other command-line options\")\n", "        return loan_csv\n", "    except getopt.GetoptError as e:\n", "        sys.stderr.write(\"%s: %s\\n\" % (args[0], e.msg))\n", "        print_help_text()\n", "        exit(2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def print_help_text():\n", "    print(\"USAGE: python lending-club-main.py [{-i |--input=}<loan-csv>]\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This function overrides Jupyter's default logger so that we can output things based on our formatting preferences"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def setup_logging():\n", "    for handler in logging.root.handlers[:]:\n", "        logging.root.removeHandler(handler)\n", "    logger = logging.getLogger()\n", "    formatter = logging.Formatter('%(message)s')\n", "    ch = logging.StreamHandler()\n", "    ch.setLevel(logging.DEBUG)\n", "    ch.setFormatter(formatter)\n", "    logger.setLevel(logging.DEBUG)\n", "    logger.addHandler(ch)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_csv(loan_csv):\n", "    return pd.read_csv(loan_csv, low_memory=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def heading(heading_text):\n", "    logging.info(\"-\" * 100)\n", "    logging.info(heading_text)\n", "    logging.info(\"-\" * 100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    setup_logging()\n", "    analyse(read_csv(parse_commandline_options(sys.argv[1:])))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}