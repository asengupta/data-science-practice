# # Running the file
# If you wish to use your own copy of the data, use the following command:
#
# ``python housing-price-main.py [{-i |--input=}<train-csv>] [-h | --help]``
#
# Here are some examples:
#
# ``python housing-price-main.py --input=train.csv``
# ``python housing-price-main.py -i train.csv``
# ``python housing-price-main.py``
# ``python housing-price-main.py --help``
#
# All of these arguments are optional. Providing no arguments makes the code read from the default location, i.e. ```./data```.
#
# # Instructions on regenerating this Jupyter Notebook
# The Jupyter notebook can be regenerated by installing P2J, like so:
#
# ``pip install p2j``
#
# and running the following:
#
# ``p2j -o code/housing-price-main.py -t notebook/housing-price-main.ipynb``

# # Library Imports
import getopt
import logging
import sys
import warnings

import pandas as pd
import seaborn as sns
import statsmodels.api as sm
from matplotlib import pyplot as plt
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from statsmodels.stats.outliers_influence import variance_inflation_factor

# # Constants
# A bunch of constants are set up so that strings don't clutter the source everywhere.

DEFAULT_DATASET_LOCATION = "../data"
DEFAULT_HOUSING_PRICE_CSV_FILENAME = "train.csv"


class Columns:
    ALLEY = "Alley"
    POOL_QUALITY = "PoolQC"
    MISC_FEATURE = "MiscFeature"
    FENCE = "Fence"
    BASEMENT_QUALITY = "BsmtQual"
    BASEMENT_CONDITION = "BsmtCond"
    BASEMENT_EXPOSURE = "BsmtExposure"
    BASEMENT_FINISHED_AREA_RATING = "BsmtFinType1"
    SECONDARY_BASEMENT_FINISHED_AREA_RATING = "BsmtFinType2"
    ELECTRICAL = "Electrical"
    GARAGE_QUALITY = "GarageQual"
    GARAGE_TYPE = "GarageType"
    GARAGE_CONDITION = "GarageCond"
    GARAGE_FINISH = "GarageFinish"
    GARAGE_YEAR_BUILT = "GarageYrBlt"
    FIREPLACE_QUALITY = "FireplaceQu"
    MASONRY_VENEER_TYPE = "MasVnrType"
    MASONRY_VENEER_AREA = "MasVnrArea"
    LOT_FRONTAGE = "LotFrontage"

# SEASON_CATEGORICAL_MAPPING = {1: SeasonConstants.SEASON_1,
#                               2: SeasonConstants.SEASON_2,
#                               3: SeasonConstants.SEASON_3,
#                               4: SeasonConstants.SEASON_4}


def with_dummies_builder(categorical_column, category_mapping):
    return lambda dataset: with_dummy_variables(dataset, categorical_column, category_mapping)

# This utility function pretty prints a dataframe for output
def log_df(dataframe_label, dataframe, num_rows=10):
    heading(dataframe_label)
    logging.info(dataframe.head(num_rows).to_string())

# This function actually performs the dummy variable setup
def with_dummy_variables(dataset, categorical_column, category_mapping):
    dummy_columns = pd.get_dummies(dataset.pop(categorical_column), drop_first=True)
    log_df(f"{categorical_column} before Renaming of Dummy Variables", dummy_columns)
    dummy_columns = dummy_columns.rename(columns=category_mapping)
    log_df(f"{categorical_column} after Renaming of Dummy Variables", dummy_columns)
    dataset_with_dummy_columns = pd.concat([dataset, dummy_columns], axis=1)
    return dataset_with_dummy_columns

def dummified(dataset):
    # map_season = with_dummies_builder(Columns.SEASON, SEASON_CATEGORICAL_MAPPING)
    # map_weather = with_dummies_builder(Columns.WEATHER, WEATHER_CATEGORICAL_MAPPING)
    # return map_weather(map_season(with_day(dataset)))
    return dataset

# # Entry Point for CRISPR
#  This function is the entry point for the entire CRISPR process. This is called by `main()`
def analyse(raw_housing_prices):
    pass


def log_mode(columns, housing_prices):
    for column in columns:
        logging.debug(f"Most Common {column}: {housing_prices[column].mode()[0]}")


def log_median(columns, housing_prices):
    for column in columns:
        logging.debug(f"Most Common {column}: {housing_prices[column].median()}")


def impute(categorical_columns, numerical_columns, housing_prices):
    for categorical_column in categorical_columns:
        housing_prices[categorical_column] = housing_prices[categorical_column].fillna(
            housing_prices[categorical_column].mode()[0])
    for categorical_column in numerical_columns:
        housing_prices[categorical_column] = housing_prices[categorical_column].fillna(
            housing_prices[categorical_column].median())

    return housing_prices


def impute_missing(raw_housing_prices):
    NUMERICAL_COLUMNS_WITH_MISSING_VALUES = [Columns.MASONRY_VENEER_AREA, Columns.LOT_FRONTAGE]
    CATEGORICAL_COLUMNS_WITH_MISSING_VALUES = [Columns.ALLEY, Columns.POOL_QUALITY, Columns.MISC_FEATURE, Columns.FENCE,
                                               Columns.BASEMENT_QUALITY,
                                               Columns.BASEMENT_CONDITION, Columns.BASEMENT_EXPOSURE,
                                               Columns.BASEMENT_FINISHED_AREA_RATING,
                                               Columns.SECONDARY_BASEMENT_FINISHED_AREA_RATING,
                                               Columns.ELECTRICAL, Columns.GARAGE_QUALITY, Columns.GARAGE_TYPE,
                                               Columns.GARAGE_CONDITION, Columns.GARAGE_FINISH,
                                               Columns.GARAGE_YEAR_BUILT, Columns.FIREPLACE_QUALITY,
                                               Columns.MASONRY_VENEER_TYPE]
    log_mode(CATEGORICAL_COLUMNS_WITH_MISSING_VALUES,
             raw_housing_prices)
    log_median(NUMERICAL_COLUMNS_WITH_MISSING_VALUES, raw_housing_prices)
    imputed_housing_prices = impute(CATEGORICAL_COLUMNS_WITH_MISSING_VALUES, NUMERICAL_COLUMNS_WITH_MISSING_VALUES,
                                    raw_housing_prices)
    return imputed_housing_prices


def cleaned(raw_housing_prices):
    heading("Null Entries BEFORE")
    null_entry_statistics = raw_housing_prices.isnull().sum() / len(raw_housing_prices.index)
    logging.info(null_entry_statistics.to_string())
    raw_housing_prices = impute_missing(raw_housing_prices)
    heading("Null Entries Statistics AFTER")
    null_entry_statistics = raw_housing_prices.isnull().sum() / len(raw_housing_prices.index)
    logging.info(null_entry_statistics.to_string())
    return raw_housing_prices


def as_ranked_map(ordered):
    dictionary = {}
    for idx, val in enumerate(ordered):
        dictionary[val]=idx + 1
    return dictionary

def ranked(raw_housing_prices):
    ranked_electricity = as_ranked_map(["ELO", "NoSeWa", "NoSewr", "AllPub"])
    print(ranked_electricity)
    # raw_housing_prices["Utilities"].map({"ELO": 1, })


def study(raw_housing_prices):
    logging.debug(raw_housing_prices.head().to_string())
    logging.debug(raw_housing_prices.shape)
    logging.debug(raw_housing_prices.columns)
    imputed_housing_prices = cleaned(raw_housing_prices)
    ranked(raw_housing_prices)
    # explore(imputed_housing_prices)
    analyse(imputed_housing_prices)

def explore(dataset):
    plt.figure()
    # Please note that generating the pairplot takes a little while due to the number of variables to plot. Please be patient while it does this.
    sns.pairplot(data=dataset)
    plt.show()
    plt.figure()
    sns.heatmap(dataset.corr(), cmap="YlGnBu", annot=True, annot_kws={"size": 5})
    plt.show()


# # Utility Functions
# This function reads command line arguments, one of which can be the input loan data set
def parse_commandline_options(args):
    print(f"args are: {args}")
    loan_csv = f"{DEFAULT_DATASET_LOCATION}/{DEFAULT_HOUSING_PRICE_CSV_FILENAME}"

    try:
        options, arguments = getopt.getopt(args, "i:hf:", ["input=", "help"])
        for option, argument in options:
            if option in ("-h", "--help"):
                print_help_text()
            elif option in ("-i", "--input"):
                loan_csv = argument
            else:
                print(f"{option} was not recognised as a valid option")
                print_help_text()
                print("Allowing to continue since Jupyter notebook passes in other command-line options")
        return loan_csv
    except getopt.GetoptError as e:
        sys.stderr.write("%s: %s\n" % (args[0], e.msg))
        print_help_text()
        exit(2)


# This function prints out the help text if either explicitly requested or in case of wrong input
def print_help_text():
    print("USAGE: python housing-price-main.py [{-i |--input=}<housing-pricing-csv>]")


# This function overrides Jupyter's default logger so that we can output things based on our formatting preferences
def setup_logging():
    warnings.filterwarnings("ignore")
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    logger = logging.getLogger()
    formatter = logging.Formatter('%(message)s')
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(formatter)
    logger.setLevel(logging.DEBUG)
    logger.addHandler(ch)


# This function reads the loan data set
def read_csv(loan_csv):
    return pd.read_csv(loan_csv, low_memory=False)


# This utility function pretty prints a heading for output
def heading(heading_text):
    logging.info("-" * 100)
    logging.info(heading_text)
    logging.info("-" * 100)


# # Main Entry Point: main()
# This function is the entry point of the script
def main():
    setup_logging()
    study(read_csv(parse_commandline_options(sys.argv[1:])))


main()
